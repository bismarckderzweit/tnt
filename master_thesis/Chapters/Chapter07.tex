%*****************************************
\chapter{Conclusion and Future Work}\label{ch:Conclusion}
%*****************************************
%\setcounter{figure}{10}
% \NoCaseChange{Homo Sapiens}
In this paper we introduce the novel problem of finding feature attribute explanations for LTR models in a local posthoc manner. We define notions of validity and completeness specifically for rankings and frame optimization problems to find a fixed size feature subset that maximizes the desired measure. We proposed a flexible framework that effectively explores the search space by optimizing for pairwise preference (extracted from the target ranked list) coverage. In our experiments on several model families and datasets we show that our approach is significantly better for LTR models in terms of validity and coverage. By comparing against the ideal feature attribution we see that our approach is the first step in this novel problem domain. We seek to experiment with approaches that are not strictly greedy by including a backtracking procedure. Additionally, with the promise of the $\epsilon$ based approaches, we envisage a more adaptive and optimization specific threshold leading to improved performance. Finally, we will explore how our approach can be adapted in a semi-blackbox setting where we have access to the learning algorithm but not the model parameters.