 
 %*****************************************
\chapter{results and Discussions}\label{ch:results}
%*****************************************
%\setcounter{figure}{10}
% \NoCaseChange{Homo Sapiens}
\begin{table*}[]
\begin{tabular}{lccccccc}
\toprule
                             & \multicolumn{5}{c}{MQ2008} \\
                             & LM   & RN    & CA      & LR     & LN    \\
\midrule
random                       & -0.13195& 	-0.24055& 	-0.2953& 	-0.0464	& -0.2483   \\
shap1                        & 0.02805& 	-0.06805& 	0.15265& 	0.08495& 	-0.0489   \\
shap5                        &  0.0518& 	-0.06105& 	0.12855& 	0.08685& 	-0.0988  \\
\midrule
v. \greedy            & 0.08365& 	-0.04105& 	0.1941& 	0.0994& 	-0.0461    \\
v. \greedycov         & 0.09935& 	-0.0557& 	0.1898& 	0.1297& 	-0.05295   \\
v. \greedycovep       & 0.0997& 	-0.00385& 	0.234& 	\textbf{0.1431}& 	\textbf{0.02435}     \\
\midrule
c. \greedy            & 0.0764& 	\textbf{0.0946}& 	0.2022& 	0.09505	&-0.0347  \\
c. \greedycov         & 0.1335& 	-0.13125& 	0.18555& 	0.1303& 	-0.11585    \\
c. \greedycovep       & \textbf{0.17405}& 	0.0367& 	\textbf{0.2352}& 	0.1295& 	0.01655  \\
\toprule
\end{tabular}
\caption{ Overview results for the \textsc{MQ2008} when k=5 }\label{tab:(v+c)_mq2008}
\end{table*}

\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
 &  \multicolumn{3}{c}{MSLR k=5} &  & \multicolumn{3}{c}{MSLR k=10} \\
                            & LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
random   &-0.1515&	-0.3123&	-0.0846&&	-0.08255&	-0.2348&	-0.0485 \\
shap1      &-0.0145&	-0.0108&	-0.0006&&	-0.0059&	0.0081&	0.0002 \\
shap5   &-0.0251&	-0.0091&	0.0043&	&-0.00015&	0.0207&	0.005  \\
\midrule
v. \greedy   & 0.0055& 	0.0014	& 0.00435&& 	0.02045& 	0.03545& 	0.00545 \\
v. \greedycov & 0.0096& 	0.00245& 	0.01845& &	0.0218& 	0.044& 	0.02055  \\
v. \greedycovep &\textbf{0.01685}& 	\textbf{0.0177}& 	\textbf{0.01925}& &	\textbf{0.0276}& 	\textbf{0.04155}& 	\textbf{0.0478}\\
\midrule
c. \greedy &  0.01005& 	0.00145	& 0.00445& &	0.02175& 	0.03415& 	0.0085  \\
c. \greedycov  & 0.0026	& -0.003& 	0.00685&&	0.01225& 	0.03765& 	-0.00255 \\
c. \greedycovep & 0.00425& 	-0.0011& 	0.0053& &	0.00705& 	0.03865& 	0.03545\\
\toprule
\end{tabular}
\caption{Overview results for the \textsc{MSLR}. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized.}\label{tab:(v+c)_mslr}
\end{table*}

Table~\ref{tab:(v+c)_mq2008} and~\ref{tab:(v+c)_mslr} provides a birds eye view of our results, here we use the combined matric that mentioned in chapter 5,  $\frac{c+v}{2}$, the value of the best algorithm for each model is bolded. Considering the mean of $\tau$ from $c$ and $v$, we first find that \textsc{SHAP1} and \textsc{SHAP5} significantly outperform the \textsc{random} baseline although there is only a significant difference between \textsc{SHAP1} and \textsc{SHAP5} for listwise approaches. Overall we see that \greedycovep optimized for validity gives us the best results. Optimizing for completeness however is a mixed bag. While explanations for pointwise model Linear Regression and pairwise models are better than \textsc{SHAP} (c. \greedy and c. \greedycov respectively), they are not considerably better for the listwise, for c. \greedycov even worse. 

v. \greedycovep is significantly better than both \textsc{SHAP} approaches and our completeness optimized variants consistently across models and datasets. For \textsc{MQ2008}, it is almost twice as good as \textsc{SHAP1} for pointwise and listwise approaches whereas it is several orders of magnitude better for pairwise approaches. This further highlights that \textsc{SHAP} is ill-suited to explaining rankings in terms of validity and completeness. Note that the range of $c$ and $v$ is $[+1,-1]$ which is why the overall results tend to be small in magnitude. These results are more indicative of the relative performance between approaches for small sized explanations $\f'$. 

In the subsequent subsections, we turn towards examining our results specifically in terms of validity and completely.

\subsection{Validity and Completeness}
\label{sec:validity}
\begin{table*}[]
\begin{tabular}{lccccccc}
\toprule
                             & \multicolumn{5}{c}{Validity} \\
                              & LM   & RN    & CA      & LR     & LN      \\
\midrule
random                       &   0.0407& 	0.237& 	0.0638& 	0.0623& 	0.1894   \\
shap1                        &   0.1242	& 0.3809& 	0.3892& 	0.1312& 	0.3431     \\
shap5                        &  0.1348& 	0.2687& 	0.3624& 	0.1329& 	0.2499    \\
\midrule
v. \greedy            & 0.2592& 	0.2872	& 0.4358& 	0.157& 	0.2901      \\
v. \greedycov         &  0.2808& 	0.2678& 	0.4149& 	0.1978& 	0.2892    \\
v. \greedycovep       &   \textbf{0.3617}& 	\textbf{0.616}& 	\textbf{0.5685}& 	\textbf{0.299}& 	\textbf{0.6134}     \\
\midrule
c. \greedy            &   0.1397& 	0.2696& 	0.4481& 	0.1673& 	0.2844 &    \\
c. \greedycov         &   0.0631& 	0.2541& 0.3819& 	0.1097& 	0.2274  &   \\
c. \greedycovep       &   0.0878& 	0.2467& 	0.4936& 	0.2665& 	0.2665 &    \\
\toprule
\end{tabular}
\caption{$\tau$  on \textsc{MQ2008}, when k=5. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized. }\label{tab:tau_mq2008_validity}
\end{table*}


\begin{table*}[]
\begin{tabular}{lccccccc}
\toprule
                             & \multicolumn{5}{c}{Completeness} \\
                             & LM   & RN    & CA      & LR     & LN      \\
\midrule
random                       & -0.3046&	-0.7181&	-0.6544&	-0.1551&	-0.686     \\
shap1                        &   -0.0681&	-0.517&	-0.0839&	0.0387&	-0.4409    \\
shap5                        &   -0.0312	&-0.3908&	-0.1053&	0.0408	&-0.4475  \\
\midrule
v. \greedy            &  -0.0919	&-0.3693	&-0.0476	&0.0418&	-0.3823     \\
v. \greedycov         &    -0.0821&	-0.3792&	-0.0353&	0.0616&	-0.3951\\
v. \greedycovep       &     -0.1623&	-0.6237&	\textbf{-0.1005}&	-0.0128&	-0.5647  \\
\midrule
c. \greedy            &  \textbf{0.0131}&	\textbf{-0.0804}&	-0.0437	&0.0228&	\textbf{-0.3538}    \\
c. \greedycov         &     -0.0138&	-0.5303&	-0.0438&	\textbf{0.0628}	&-0.5209\\
c. \greedycovep       &  -0.0136&	-0.5426&	-0.0981&	-0.04&	-0.5803  \\
\toprule
\end{tabular}
\caption{$\tau$ on \textsc{MQ2008},when k=5. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized. }\label{tab:tau_mq2008_comp}
\end{table*}


\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           

 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             & LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
random   & 0.0029& 	0.0094& 	-0.0001 && -0.1721&	-0.634&	-0.3029  \\
shap1      &0.0058& 	0.0497& 	0.0233 & &-0.007&	-0.0713&	-0.0523  \\
shap5   &  0.0090& 	0.0488& 	0.001  &&-0.0004&	-0.0670&	-0.0512 \\
\midrule
v. \greedy   & 0.0077& 	0.0602& 	0.0449 && 0.001	&-0.0574	&-0.0339  \\
v. \greedycov &  0.0345& 	0.0696& 	0.0588& &0.0024	&-0.0647	&-0.0396  \\
v. \greedycovep & \textbf{0.0586}& 	\textbf{0.109}& 	\textbf{0.0747}  & &-0.0201&	-0.0736&	-0.041\\
\midrule
c. \greedy &  0.0091& 	0.0521& 	0.0244& &-0.0002	&\textbf{-0.0492}	&-0.0043 \\
c. \greedycov  &  0.0111& 	0.0521& 	0.0249&&	\textbf{0.0026}	&-0.0581&	-0.0197  \\
c. \greedycovep & 0.0266& 	0.0656& 	0.0277&  &-0.016&	-0.0678&	\textbf{-0.0192}\\
\toprule
\end{tabular}
\caption{$\tau$ on \textsc{MSLR} when k=5. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized.}\label{tab:tau_mslr5}
\end{table*}

\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             & LR   & RB   & LM && LR   & RB   & LM      \\
\midrule
random   &0.0118 &0.0097 &	0.0097  & &  -0.1088 &	-0.4793 &	-0.1748\\
shap1      &0.0074 &	0.0572 &	0.0227   & & -0.007	 &-0.0410	 &-0.0345\\
shap5   &  0.0104 &	0.083 &	0.0307     &&-0.0004 &	-0.0415 &	-0.0310\\
\midrule
v. \greedy   &0.0114 &	0.0975	 &0.0578  & &  -0.0005	 &-0.0266 &	-0.0169  \\
v. \greedycov &   0.0401 &	0.1078 &	0.0634  & &   0.001 &	-0.0198	 &-0.0198\\
v. \greedycovep & \textbf{0.0973} &	\textbf{0.1382} &	\textbf{0.0862}   & &  -0.0017 &	-0.0551 &	-0.031\\
\midrule
c. \greedy & 0.014	 &0.0869 &	0.0346   & &  \textbf{0.003} &	-0.0186 &	\textbf{0.0089} \\
c. \greedycov  &  0.0147 &	0.0951 &	0.0376 & &    -0.0198 &	\textbf{-0.0198} &	-0.0131\\
c. \greedycovep & 0.0743 &	0.1063	 &0.0255   & & -0.0034 &	-0.029 &	-0.0114	\\
\toprule
\end{tabular}
\caption{$\tau$ on \textsc{MSLR} when k=10. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized.}\label{tab:tau_mslr10}
\end{table*}

A valid explanation is one that carries enough information to recreate the target output $\pi$ with high fidelity. Our measurement of fidelity is $\tau$ where correlation values above $0.25$ are already considered to be moderate correlation and above $0.5$ is strong correlation. We measure the completeness of an explanation by finding a set of features which when removed change the target ranking, i.e. low fidelity. To make the measure consistent with validity (i.e. higher the better) we consider $-\tau$. Tables~\ref{tab:tau_mq2008_validity} to~\ref{tab:tau_mslr10} show the tau of validity and completeness measurements across models for both datasets. Note that we measure completeness and validity for all methods even if they are not directly optimized for it.

In Table~\ref{tab:tau_mq2008_validity} and~\ref{tab:tau_mq2008_comp}, where our explanations are only 5 features long, we first observe the validity results and the validity optimized approaches. We find that v. \greedycovep is significantly better than all other approaches by a large margin for all the models. When considering only variants of our method we find that going from a pure greedy feature selection (v. \greedy) to a coverage based selection (v. \greedycov) does not always yield improvements (see pointwise). However a coverage based selection with a threshold yields large improvements. This indicates that by essentially ignoring pairs (removed from the preference matrix iteratively) where the score difference is positive and large, allows our method to select non-redundant features that are more informative in recreating $\pi$. For the pairwise model RankNet in particular, using only 5 features we are able to produce a $\pi'$ that is very strongly correlated (0.616) with $\pi$. 

Turning towards completeness, a trend we tend to see in all completeness measures is the seemingly low values. This simply means that while a small number of features may prove to be sufficient for good valid explanations, the same does not hold for completeness. From all our experiments, we see that larger feature subsets are needed to effectively find a complete explanation in the real world. This is inherently due to feature redundancy and correlations found in real world data. Simply removing a seemingly important feature may not affect completeness if there exists another feature correlated to it that the LTR model also focuses on. However large feature subsets tend be unwieldy as explanations for humans. Hence we observe the performance of our approaches in selecting a small feature subset that has a relatively high impact on completeness. Note that a value close to 0 does not mean the method is ineffective. It instead implies that exactly half of the concordant pairs in $\pi$ are discordant in $\pi'$ by just removing $k=5$ features.

Now we examine the completeness metric for completeness optimized approaches. We see that at least one of our variants outperforms both \textsc{SHAP} approaches for all models. The choice of variant is highly dependent on the type of model. c. \greedy tends to be the best choice for the LambdaMART, RankNet and ListNet model whereas c. \greedycov is best for Linear Regression model. For model Coordinate Ascent, the completeness optimized approaches seems not very good, the best approach is even v. \greedycovep. We find empirically that using our selected threshold when optimizing for completeness is a suboptimal choice. In our experiments we use the same threshold computation method for validity and completeness optimization. We leave threshold tuning specifically for completeness to future work.

When observing the performance of validity optimized approaches for the completeness metric and vice versa, interesting findings emerge. Immediately we notice that optimizing for validity also tends to give us reasonable results for completeness but not necessarily when doing the opposite. v. \greedycov tends to strike a seemingly good balance between completeness and validity for the pairwise model. Also we see that v. \greedycov has the second best completeness for the pointwise model albeit without a significant difference when compared to c. \greedycov. For the listwise model however, optimizing for completeness always yields the best results.

Finally we observe Table~\ref{tab:tau_mslr10}. Since \textsc{MSLR} has 3 times as many features as \textsc{MQ2008}, we look at both $k=5$ and $k=10$. All of the same trends hold here with v. \greedycovep being the best approach for the validity metrics and surprisingly for completeness for the LambdaMART model when $k=5$. Must mention that \greedy approaches do a much better work on MSLR than MQ2008 for completeness, that is because MSLR has more features, it will not easy to stop due to the reduce of positive cells, it is robuster.

From table~\ref{tab:ndcg_mq2008_validity} to \ref{tab:ratio_mslr10} are the collated results in other metrics of the approches we finally choosed.


\begin{table*}[]

\begin{tabular}{lccccccc}
\toprule
                             & \multicolumn{5}{c}{Validity} \\
                             & LM   & RN    & CA      & LR     & LN      \\
\midrule
random                       & 0.2841& 	0.0812& 	0.1349& 	0.1942& 	0.0722   \\
shap1                        &  \textbf{0.0699}& 	0.0391& 	0.0341& 	0.0695& 	0.0408   \\
shap5                        &  0.1423& 	0.0876& 	0.0605& 	0.097& 	0.0696   \\
\midrule
v. \greedy            &    0.0826& 	0.0755& 	0.038& 	0.081& 	0.056   \\
v. \greedycov         &    0.0876& 	0.0747	& 0.0421& 	0.1045& 	0.0639 \\
v. \greedycovep       &    0.1644& 	\textbf{0.0338}& 	0.0268& 	0.1033& 	\textbf{0.0376}   \\
\midrule
c. \greedy            &   0.132& 	0.0804& 	0.0441& 	0.0829& 	0.0705   \\
c. \greedycov         &   0.1632& 	0.0908& 	0.044& 	0.1219	& 0.0754 \\
c. \greedycovep       &    0.1542& 	0.0857& 	\textbf{0.0262}& 	\textbf{0.0665}& 	0.0665   \\
\toprule
\end{tabular}
\caption{$\Delta NDCG$ on \textsc{MQ2008}}\label{tab:ndcg_mq2008_validity}
\end{table*}





\begin{table*}[]

\begin{tabular}{lccccccc}
\toprule
                             & \multicolumn{5}{c}{Completeness} \\
                             & LM   & RN    & CA      & LR     & LN     \\
\midrule
random                       &   0.0329& 	0.0115& 	0.0196& 	0.1015& 	0.0025  \\
shap1                        &   0.2261& 	0.0281& 	0.1421& 	0.2615& 	\textbf{0.051} \\
shap5                        &   0.1742	& 0.0329& 	0.1129& 	0.2666& 	0.0377 \\
\midrule
v. \greedy            &   0.1236& 	0.0397& 	0.1365& 	\textbf{0.2684}& 	0.0354    \\
v. \greedycov         &    0.1024& 	0.0385	& 0.1413& 	0.2555& 	0.0374\\
v. \greedycovep       &     0.0739& 	0.0238& 	0.0877& 	0.1965& 	0.019 \\
\midrule
c. \greedy            &   \textbf{0.2656}& 	\textbf{0.0582}& 	0.1341& 	0.2676& 	0.0381 \\
c. \greedycov         &   0.2212& 	0.0263& 	\textbf{0.1452}& 	0.2482& 	0.0288  \\
c. \greedycovep       &   0.2605& 	0.0255& 	0.1163& 	0.0218& 	0.0218\\
\toprule
\end{tabular}
\caption{$\Delta NDCG$ for the \textsc{MQ2008}   }\label{tab:ndcg_mq2008_comp}
\end{table*}

\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                            & LR   & RB   & LM && LR   & RB   & LM      \\
\midrule
random   & 0.1528& 	0.1908& 	0.2854& &    0.0411	& 0.0147& 	0.0262\\
shap1      & 0.1336	& \textbf{0.0684}& 	\textbf{0.1092}  & &  0.1543& 	0.1053& 	0.1682\\
shap5   & 0.1349& 	0.0772& 	0.3249 & &   \textbf{0.1642}& 	0.1021& 	0.1678\\
\midrule
v. \greedy   &  0.1326& 	0.077& 	0.1218  & &  0.1635& 	\textbf{0.1635}	& 0.1635\\
v. \greedycov &   0.1282& 	0.0763& 	0.1211 & &   0.1636&	0.1048& 	0.1577 \\
v. \greedycovep & 0.1269& 	0.0891	& 0.1541 & &   0.1392& 	0.0746	& 0.1296\\
\midrule
c. \greedy &   0.1383	& 0.0749& 	0.1237  & &  0.1565& 	0.1565& 	0.1565\\
c. \greedycov  & 0.1388& 	0.0801& 	0.1218 & &   0.1624& 	0.1078& 	0.2062 \\
c. \greedycovep &\textbf{0.1225}	& 0.0698& 	0.1249& & 0.1592& 	0.1001& 	\textbf{0.2217}	\\
\toprule
\end{tabular}
\caption{$\Delta NDCG$ on \textsc{MSLR} when k=5. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized.}\label{tab:ndcg_mslr5}
\end{table*}

\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             & LR   & RB   & LM && LR   & RB   & LM      \\
\midrule
random   &0.1433& 	0.1697& 	0.2734 & &    0.0626& 	0.0246& 	0.042\\
shap1      & 0.1337& 	0.0779& 	0.1037 & &   0.154& 	0.1516& 	0.1996\\
shap5   &  0.1399& 	0.0547& 	\textbf{0.0904} & &   0.1648& 	0.1544& 	0.2307\\
\midrule
v. \greedy   & 0.1322& 	0.0559& 	0.0945 & &  0.1643& 	0.1621& 	0.2082 \\
v. \greedycov &  0.13& 	0.0565& 	0.103 & &   \textbf{0.1648}& 	0.1617& 	0.2077  \\
v. \greedycovep &  0.0751& 	0.0638& 	0.1308& &   0.1458& 	0.0892	& 0.1557\\
\midrule
c. \greedy &  0.1382& 	0.0552	& 0.1032 & &  0.1574& 	0.165& 	0.2599  \\
c. \greedycov  & 0.1365	& 0.0504& 	0.1005 & & 0.1622& 	\textbf{0.1701}& 	0.257	    \\
c. \greedycovep & \textbf{0.0652}& 	\textbf{0.0434}& 	0.1012& &   0.1442& 	0.1569	& \textbf{0.2812}\\
\toprule
\end{tabular}
\caption{$\Delta NDCG$ on \textsc{MSLR} when k=10. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized.}\label{tab:ndcg_mslr10}
\end{table*}


\begin{table*}[]

\begin{tabular}{lccccccc}
\toprule
                             & \multicolumn{5}{c}{Validity} \\
                            & LM   & RN    & CA      & LR     & LN      \\
\midrule
random                       &  0.2921&	0.1308&	0.2045&	0.2944&	0.1244  \\
shap1                        &   \textbf{0.0727}&	0.0665&	0.059&	0.1157&	0.0753  \\
shap5                        & 0.1464&	0.1518&	0.0963&	0.1571&	0.1133    \\
\midrule
v. \greedy            &   0.1272&	0.1267&	0.058&	0.1298&	0.1066    \\
v. \greedycov         &  0.0904	&0.1215	&0.069&	0.1595&	0.1091   \\
v. \greedycovep       &   0.1694&	\textbf{0.0582}	&0.044&	0.1544&	\textbf{0.0672}    \\
\midrule
c. \greedy            &    0.1353&	0.1315&	0.0645	&0.13&	0.1271  \\
c. \greedycov         &   0.1667&	0.148&	0.0648&	0.1888&	0.1374 \\
c. \greedycovep       &   0.1582&	0.1393&	\textbf{0.0418}&	\textbf{0.1115}&	0.1115    \\
\toprule
\end{tabular}
\caption{NDCG ratio on \textsc{MQ2008} }\label{tab:ratio_mq2008_validity}
\end{table*}

\begin{table*}[]
\begin{tabular}{lccccccc}
\toprule
                             & \multicolumn{5}{c}{Completeness} \\
                             & LM   & RN    & CA      & LR     & LN    \\
\midrule
random                       & 0.0343&	0.0229&	0.03&	0.0853&	0.0061    \\
shap1                        &  0.2311&	0.0419&	0.207&	0.3748&	\textbf{0.0811}  \\
shap5                        &  0.1796&	0.0554&	0.1702&	0.3783&	0.0497  \\
\midrule
v. \greedy            &     0.1272&	0.0683&	0.2011&	0.3775&	0.061  \\
v. \greedycov         &  0.1062	&0.0665	&\textbf{0.219}&	0.3647&	0.0622  \\
v. \greedycovep       &    0.0758&	0.0385	&0.1384&0.2951&	0.0372  \\
\midrule
c. \greedy            &    \textbf{0.2713}&	\textbf{0.344}	&0.2048	&0.3777&	0.0676\\
c. \greedycov         &   0.2264&	0.0429&	0.2105&	0.3599&	0.0498  \\
c. \greedycovep       & 0.2668	&0.0392	&0.1741	&\textbf{0.5803}&	0.04  \\
\toprule
\end{tabular}
\caption{NDCG ratio on \textsc{MQ2008}  }\label{tab:ratio_mq2008_comp}
\end{table*}


\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                           & LR   & RB   & LM && LR   & RB   & LM      \\
\midrule
random   & 0.8784& 	0.5732& 	0.5684 & &  0.2374& 	0.0552& 	0.0687\\
shap1      & 0.7143& 	0.2419& 	\textbf{0.2648} & &  0.8383& 	\textbf{0.4043}& 	0.3549\\
shap5   &  \textbf{0.6604}& 	\textbf{0.2382}& 	0.6516 & &  0.8651& 	0.3732& 	0.3663\\
\midrule
v. \greedy   & 0.7575& 	0.2706& 	0.2825  & &  0.8073& 	0.3416	& 0.3416 \\
v. \greedycov &   0.7681& 	0.2713& 	0.2769  & &  0.8145	& 0.3241& 	0.2484\\
v. \greedycovep & 0.8449& 	0.3368& 	0.3286& &   0.7946& 	0.2436& 	0.3257\\
\midrule
c. \greedy &   0.7723& 	0.2634& 	0.2914  & & 0.8002& 	0.3706& 	0.3706	 \\
c. \greedycov  &   0.8013& 	0.2651& 	0.2828 & &   0.8268	& 0.3352& 	0.4229\\
c. \greedycovep & 0.8265& 	0.241& 	0.293 & &  \textbf{1.1337}& 	0.3332& 	\textbf{0.4714}\\
\toprule
\end{tabular}
\caption{NDCG ratio on \textsc{MSLR} when k=5. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized.}\label{tab:ratio_mslr5}
\end{table*}

\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           

 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                            & LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
random   & 0.9463&	0.5024&	0.5374 && 0.3643&	0.0845&	0.0997\\
shap1      &0.719&	0.2759&	0.2526 && 0.8383&	0.5360&	0.4112 \\
shap5   &0.7219	&0.1787	&\textbf{0.2132} &&  \textbf{0.8676}&	0.5323&	0.4683 \\
\midrule
v. \greedy   &0.7541&	0.1925&	0.2228 &&  0.8102&	0.5058&	0.4193  \\
v. \greedycov & 0.7906&	0.7906&	0.2323 &&  0.8133&	0.4921	&0.4106   \\
v. \greedycovep & 0.5075&	0.5075&	0.2676 && 0.817&	0.2981&	0.3295 \\
\midrule
c. \greedy &0.7692&	0.1945&	0.2467&&  0.7997&	0.5068&	0.5044    \\
c. \greedycov  & 0.8013&	0.2651&	0.2986&&  0.8456&	\textbf{0.5361}&	0.5157   \\
c. \greedycovep &\textbf{0.3963}&	\textbf{0.1446}&	0.2308&&  0.8494&	0.5105	&\textbf{0.5493} \\
\toprule
\end{tabular}
\caption{NDCG ratio on \textsc{MSLR} when k=10. Approaches prefixed with $c$ refer to completeness optimized whereas $v$ refers to validity optimized.}\label{tab:ratio_mslr10}
\end{table*}


\subsection{Alpha}
In the approach alpha we make a trade off between validity optimized approach and completeness optimized approach. It conbines the preference matrix of validity and completeness with a parameter $\alpha$, for a feature, if its validity score for one document is $v$, the completeness score is $c$, then the alpha score is:

\begin{equation}
\begin{aligned}
score_{\alpha } = \alpha \cdot v+(1-\alpha )\cdot c
\end{aligned}
\label{eqn:scorealpha}
\end{equation}
alpha can be choosed as 0.1,0.3,0.5,0.7 or 0.9. 


\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RN   & LM && LR   & RN   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, $\tau$ on \textsc{MQ2008} when k=5.}\label{tab:tau_mq2008_alpha}
\end{table*}

\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, $\tau$ on \textsc{MQ2008} when k=5.}\label{tab:tau_mslr_alpha5}

\end{table*}
\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, $\tau$ on \textsc{MQ2008} when k=10.}\label{tab:tau_mslr_alpha10}
\end{table*}




\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RN   & LM && LR   & RN   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, $NDCG$ on \textsc{MQ2008} when k=5.}\label{tab:ndcg_mq2008_alpha}
\end{table*}

\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, $NDCG$ on \textsc{MSLR} when k=5.}\label{tab:ndcg_mslr_alpha5}
\end{table*}
\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, $NDCG$ on \textsc{MSLR} when k=10.}\label{tab:ndcg_mslr_alpha10}
\end{table*}




\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RN   & LM && LR   & RN   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, NDCG ratio on \textsc{MQ2008} when k=5.}\label{tab:ratio_mq2008_alpha}
\end{table*}


\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, NDCG ratio on \textsc{MSLR} when k=5.}\label{tab:ratio_mq2008_alpha5}
\end{table*}

\begin{table*}[]
\begin{tabular}{lcccccccc}
\toprule
                           
 &  \multicolumn{3}{c}{Validity} &  & \multicolumn{3}{c}{Completeness} \\
                             $\alpha$& LR   & RB   & LM && LR   & RB   & LM     \\
\midrule
0.1 & \\
0.3 & \\
0.5 & \\
0.7 & \\
0.9 &  \\
\toprule
\end{tabular}
\caption{Alpha approach, NDCG ratio on \textsc{MSLR} when k=10.}\label{tab:ratio_mq2008_alpha10}
\end{table*}















\subsection{Discussion}
\textbf{Distance from ideal}: Since our proposed greedy heuristic does not provide theoretical error bounds or guarantees, we conducted further experiments to empirically determine how far away from the ideal we are. To illustrate our findings we consider a listwise and pairwise model for \textsc{MQ2008} since the overall number of input features is small. We used brute force to find the ideal feature subset (k=3) that maximizes validity. We find that for the pairwise model the validity of the ideal feature set is $0.86$ on average. Our best approach produces a subset $\f'$ (k=5) that achieves an average validity of $0.61$ which shows that even if we make sub-optimal choices in the beginning we are able to exploit pairwise preferences effectively to eventually construct an explanation that is closer to the ideal than all the other approaches. 

\textbf{Practical use cases}: The approaches in this paper are specific to ranked lists whereas \textsc{SHAP} is better suited to classification or regression problems. \textsc{SHAP} is also the right choice when trying to identify the features most responsible for the relevance score of a given document. However the shapley value estimates are highly dependent on the calibration of the base value. Further \textsc{SHAP} inherently is neither optimized for validity nor completeness. The approaches we suggest are geared towards finding valid or complete feature attribution explanations. High validity explanations are useful when try to determine the key features responsible for rank order for a given query. For instance, in product search, one may seek to find the most important features influencing a ranking for popular queries -- Do the user features matter more when every other feature is removed/set to the expected value? High completeness explanations on the other hand can be viewed as a set of features that the ranker is sensitive to for a given query. Such sensitive features once identified can be used to construct adversarial attacks or increase the robustness of the ranker.

% how do we do when we vary the number of features selected. 3,5,7 -- how far are we from the ideal value for 3 features